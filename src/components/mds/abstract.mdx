# Abstract

To address the inherent challenges of low resolution and detail deficiency in infrared videos, this paper proposes a visible-referenced inf video super-resolution framework. To tackle the feature matching difficulty arising from the modality gap between infrared and visible domains, our method introduces an innovative cross-modal feature matching module. This module efficiently mines and transfers high-frequency textures from the visible-light video to guide the high-fidelity reconstruction of the infrared video. Experiments demonstrate that our proposed method outperforms existing approaches in both quantitative and qualitative evaluations. Specifically, it achieves a PSNR improvement of 0.31 dB over the second-best model and generates visual results with richer textures and fewer artifacts. This work offers an effective solution for cross-modal video enhancement and holds significant application value in fields such as security surveillance and remote sensing.